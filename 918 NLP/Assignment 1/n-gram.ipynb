{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmatized.txt', 'r') as lemmatized_file:\n",
    "    lemmatized = lemmatized_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens (N): 5696406\n",
      "Vocabulary Size (V): 123026\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all preprocessed texts into a single string\n",
    "concatenated_text = ' '.join(lemmatized)\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = concatenated_text.split()\n",
    "\n",
    "# Calculate N (number of tokens)\n",
    "N = len(tokens)\n",
    "\n",
    "# Calculate V (vocabulary size)\n",
    "V = len(set(tokens))\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of Tokens (N):\", N)\n",
    "print(\"Vocabulary Size (V):\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Trigrams:\n",
      "('one', 'of', 'the'): 2434\n",
      "('on', 'share', 'of'): 2095\n",
      "('on', 'the', 'stock'): 1567\n",
      "('as', 'well', 'a'): 1418\n",
      "('in', 'research', 'report'): 1415\n",
      "('in', 'research', 'note'): 1373\n",
      "('be', 'able', 'to'): 1267\n",
      "('the', 'united', 'state'): 1223\n",
      "('for', 'the', 'quarter'): 1221\n",
      "('average', 'price', 'of'): 1193\n",
      "('research', 'report', 'on'): 1177\n",
      "('research', 'note', 'on'): 1138\n",
      "('the', 'end', 'of'): 1135\n",
      "('share', 'of', 'the'): 1133\n",
      "('in', 'report', 'on'): 1124\n",
      "('earnings', 'per', 'share'): 1121\n",
      "('cell', 'phone', 'plan'): 1073\n",
      "('phone', 'plan', 'detail'): 1070\n",
      "('accord', 'to', 'the'): 1064\n",
      "('buy', 'rating', 'to'): 1016\n",
      "('of', 'the', 'company'): 1002\n",
      "('appear', 'first', 'on'): 994\n",
      "('day', 'move', 'average'): 993\n",
      "('price', 'target', 'on'): 981\n",
      "('be', 'one', 'of'): 970\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "# Count the occurrences of each trigram\n",
    "trigram_counts = Counter(trigrams)\n",
    "\n",
    "# Get the top 25 trigrams\n",
    "top_25_trigrams = trigram_counts.most_common(25)\n",
    "\n",
    "# Output the results\n",
    "print(\"Top 25 Trigrams:\")\n",
    "for trigram, count in top_25_trigrams:\n",
    "    print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Word Count: 176422\n",
      "Negative Word Count: 143142\n"
     ]
    }
   ],
   "source": [
    "# Read positive and negative word lists\n",
    "with open('signal-news1/opinion-lexicon-English/positive-words.txt', 'r') as positive_file:\n",
    "    positive_words = set(positive_file.read().splitlines())\n",
    "\n",
    "with open('signal-news1/opinion-lexicon-English/negative-words.txt', 'r') as negative_file:\n",
    "    negative_words = set(negative_file.read().splitlines())\n",
    "\n",
    "# Count the occurrences of positive and negative words\n",
    "positive_word_count = sum(1 for word in tokens if word in positive_words)\n",
    "negative_word_count = sum(1 for word in tokens if word in negative_words)\n",
    "\n",
    "# Output the results\n",
    "print(\"Positive Word Count:\", positive_word_count)\n",
    "print(\"Negative Word Count:\", negative_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news stories with more positive than negative words: 10435\n",
      "Number of news stories with more negative than positive words: 6893\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Initialize counters\n",
    "more_positive = 0\n",
    "more_negative = 0\n",
    "\n",
    "# Iterate through each news story\n",
    "for news_story in lemmatized:\n",
    "    # Tokenize the news story into words\n",
    "    tokens = nltk.word_tokenize(news_story)\n",
    "\n",
    "    # Count the occurrences of positive and negative words\n",
    "    positive_word_count = sum(1 for word in tokens if word in positive_words)\n",
    "    negative_word_count = sum(1 for word in tokens if word in negative_words)\n",
    "\n",
    "    # Compare positive and negative word counts\n",
    "    if positive_word_count > negative_word_count:\n",
    "        more_positive += 1\n",
    "    elif negative_word_count > positive_word_count:\n",
    "        more_negative += 1\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of news stories with more positive than negative words:\", more_positive)\n",
    "print(\"Number of news stories with more negative than positive words:\", more_negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
